{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4abd6565-3c84-4d5b-8cfc-a07c26b48f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10467e13-ea86-4fad-9341-a73b14c7e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Literal, Namespace, RDF, URIRef, XSD, RDFS, SOSA, ConjunctiveGraph\n",
    "from rdflib.plugins.stores import sparqlstore\n",
    "from rdflib.graph import DATASET_DEFAULT_GRAPH_ID as default\n",
    "from SPARQLWrapper import SPARQLWrapper, POST, DIGEST\n",
    "import requests\n",
    "import json\n",
    "from shapely.geometry import shape\n",
    "import os\n",
    "import xarray as xr\n",
    "os.chdir(\"/workspaces/aqqa-kg-creation-dev/\")\n",
    "from observableProperties import variables_dict\n",
    "from src.utils import unix_ts_to_date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeba7684-af42-43c8-9d1f-89507cfdf06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the namespaces\n",
    "aqqa = Namespace(\"http://example.com/ontologies/aqqa#\")\n",
    "geo = Namespace(\"http://www.opengis.net/ont/geosparql#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "sf = Namespace(\"http://www.opengis.net/ont/sf#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a08bd5b5-ee2f-4564-949b-4cd489eff34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph\n",
    "g = Graph()\n",
    "g.bind(\"aqqa\", aqqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525b3cae-4f1d-482d-9476-e7e13ed2e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading ref raster cells\n",
    "ref_raster_geojson = \"/mnt/data/processed/ref_raster.geojson\"\n",
    "with open(ref_raster_geojson, \"r\") as f:\n",
    "    geojson_data = json.load(f)\n",
    "\n",
    "features = geojson_data.get(\"features\", [])\n",
    "geometries = [feature.get(\"geometry\") for feature in features]\n",
    "indexes = [feature.get(\"properties\")[\"index\"] for feature in features]\n",
    "shapely_geometries = [shape(geometry).wkt for geometry in geometries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9f20c9-14fb-4f31-b1f9-2576f6b1f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading geometries and Features of interest into RDF graph\n",
    "for i, (index, geom) in enumerate(zip(indexes, shapely_geometries)):\n",
    "    \n",
    "    ent_geom_cell = URIRef(aqqa[f\"GeomCell_{index[0]}{index[1]}\"])   \n",
    "    ent_cell = URIRef(aqqa[f\"Cell_{index[0]}{index[1]}\"])   \n",
    "    ent_hasID = URIRef(aqqa[\"hasID\"])\n",
    "\n",
    "    g.add((ent_cell, RDF.type, SOSA.FeatureOfInterest))\n",
    "    g.add((ent_cell, ent_hasID, Literal(i)))\n",
    "    g.add((ent_cell, geo.hasGeometry, ent_geom_cell))\n",
    "    \n",
    "    g.add((ent_geom_cell, RDF.type, sf.Geometry))\n",
    "    g.add((ent_geom_cell, geo.asWKT, Literal(geom, datatype=geo.wktLiteral)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c1143f-bdad-4d9e-8691-2db8c0073d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in observable properties into RDF Graph\n",
    "for var in variables_dict:\n",
    "\n",
    "    ent_obs_prop = URIRef(aqqa[f\"{var}\"])\n",
    "    ent_has_unit = URIRef(aqqa[\"hasUnit\"])\n",
    "    ent_avg_period = URIRef(aqqa[\"averagingPeriod\"])\n",
    "\n",
    "    g.add((ent_obs_prop, RDF.type, SOSA.ObservableProperty))\n",
    "    g.add((ent_obs_prop, RDFS.label, Literal(variables_dict[var][\"label\"])))\n",
    "    g.add((ent_obs_prop, ent_has_unit, Literal(variables_dict[var][\"hasUnit\"])))\n",
    "    g.add((ent_obs_prop, ent_avg_period, Literal(variables_dict[var][\"averagingPeriod\"])))\n",
    "    g.add((ent_obs_prop, RDFS.comment, Literal(variables_dict[var][\"comment\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c92303-baa3-4167-a46c-42b7102d3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in observations into RDF Graph\n",
    "year = \"2020\"\n",
    "month = \"01\"\n",
    "for var_name in variables_dict:\n",
    "    path_to_nc_file = f\"/mnt/data/processed/CAMS_AQ_AOI_AGG/{year}/{month}/cams_aq_{var_name.lower()}_{year}{month}.nc\"\n",
    "    ds = xr.open_dataset(path_to_nc_file) \n",
    "    measurement_var = ds.variables[var_name.lower()]\n",
    "    time_var = ds.variables[\"time\"]\n",
    "\n",
    "    for t_i, time in enumerate(time_var):\n",
    "        for row_i in range(measurement_var.data.shape[1]):\n",
    "            for col_i in range(measurement_var.data.shape[2]):\n",
    "                \n",
    "                t = unix_ts_to_date_str(time.item())\n",
    "                measurement_value = measurement_var.data[t_i, row_i, col_i]\n",
    "                \n",
    "                ent_obs = URIRef(aqqa[f\"Cell_{row_i}{col_i}_ts_{t}_var_{var_name}\"])\n",
    "                ent_cell = URIRef(aqqa[f\"Cell_{row_i}{col_i}\"])   \n",
    "                ent_obs_prop = URIRef(aqqa[f\"{var_name}\"])\n",
    "    \n",
    "                g.add((ent_obs, RDF.type, SOSA.Observation))\n",
    "                g.add((ent_obs, SOSA.hasFeatureOfInterest, ent_cell))\n",
    "                g.add((ent_obs, SOSA.observedProperty, ent_obs_prop))\n",
    "                g.add((ent_obs, SOSA.hasSimpleResult, Literal(measurement_value)))\n",
    "                g.add((ent_obs, SOSA.resultTime, Literal(t, datatype=XSD.date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e3eded-1773-43cc-82c7-50988a8cb398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad25946d-40cf-4537-b522-23b87eceeaef",
   "metadata": {},
   "source": [
    "### Some example queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6bd2ce-d6ea-46c9-b287-248aa165ec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 Results:\n",
      "2020-01-02 35.232746 µg m-3 None http://example.com/ontologies/aqqa#Cell_01\n",
      "2020-01-03 35.272137 µg m-3 None http://example.com/ontologies/aqqa#Cell_01\n",
      "2020-01-04 15.603108 µg m-3 None http://example.com/ontologies/aqqa#Cell_01\n",
      "2020-01-05 22.24642 µg m-3 None http://example.com/ontologies/aqqa#Cell_01\n",
      "2020-01-06 29.234375 µg m-3 None http://example.com/ontologies/aqqa#Cell_01\n",
      "2020-01-07 35.990887 µg m-3 None http://example.com/ontologies/aqqa#Cell_01\n",
      "2020-01-08 40.488934 µg m-3 None http://example.com/ontologies/aqqa#Cell_01\n",
      "2020-01-09 40.826824 µg m-3 None http://example.com/ontologies/aqqa#Cell_01\n",
      "2020-01-10 32.11849 µg m-3 None http://example.com/ontologies/aqqa#Cell_01\n"
     ]
    }
   ],
   "source": [
    "# Execute Query 1 (get variable, time and result of all observations)\n",
    "query1 = \"\"\"    \n",
    "        SELECT ?var ?unit ?time ?measurement ?foI\n",
    "        WHERE {\n",
    "            ?s a sosa:Observation ;\n",
    "               sosa:resultTime ?time ;\n",
    "               sosa:hasSimpleResult ?measurement ;\n",
    "               sosa:observedProperty [ rdfs:label \"NO2\"; aqqa:hasUnit ?unit ] ;\n",
    "               sosa:hasFeatureOfInterest [ aqqa:hasID 1 ] .\n",
    "            \n",
    "            ?foI aqqa:hasID 1 .\n",
    "            \n",
    "            FILTER (?time >= \"2020-01-02\"^^xsd:date && ?time <= \"2020-01-10\"^^xsd:date)\n",
    "        }\n",
    "        LIMIT 10\n",
    "       \"\"\"\n",
    "\n",
    "results1 = g.query(query1)\n",
    "print(\"Query 1 Results:\")\n",
    "for row in results1:\n",
    "    print(f\"{row['time']} {row['measurement']} {row['unit']} {row['var']} {row['foI']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb4e66-e5bf-4687-878f-915b8ca37f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff2a4089-9555-4688-aef1-3eb93eeadcd9",
   "metadata": {},
   "source": [
    "### Uploading RDF data to Strabon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4713e60d-07b8-4ddb-9d9d-21ce775dbc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re, os\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import shutil\n",
    "import httplib2, urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6ce13bb-72d2-4ab6-9a5c-c88fa683df66",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit(\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[64], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(argv):\n\u001b[1;32m      3\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> PREFIX strdf: <http://strdf.di.uoa.gr/ontology#> PREFIX noa: <http://teleios.di.uoa.gr/ontologies/noaOntology.owl#> SELECT ?H (strdf:transform(?HGEO, <http://www.opengis.net/def/crs/EPSG/0/4326>) AS ?GEO) WHERE \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m ?H rdf:type noa:Hotspot . ?H noa:hasAcquisitionTime ?HAT . FILTER(str(?HAT) = \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2010-08-21T21:20:00\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) . ?H noa:isDerivedFromSensor ?HS . FILTER(str(?HS) = \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSG1_RSS\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ) . ?H noa:hasGeometry ?HGEO . }\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSPARQLQuery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mXML\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/x-www-form-urlencoded\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/xml\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#conn = httplib.HTTPConnection(\"papos.space.noa.gr:8080\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#conn.request(\"POST\", \"/endpoint/Query\", params, headers)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/aqqa/lib/python3.8/urllib/parse.py:383\u001b[0m, in \u001b[0;36murlparse\u001b[0;34m(url, scheme, allow_fragments)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21murlparse\u001b[39m(url, scheme\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, allow_fragments\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124;03m\"\"\"Parse a URL into 6 components:\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    Note that we don't break the components up in smaller bits\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m     url, scheme, _coerce_result \u001b[38;5;241m=\u001b[39m \u001b[43m_coerce_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     splitresult \u001b[38;5;241m=\u001b[39m urlsplit(url, scheme, allow_fragments)\n\u001b[1;32m    385\u001b[0m     scheme, netloc, url, query, fragment \u001b[38;5;241m=\u001b[39m splitresult\n",
      "File \u001b[0;32m/opt/conda/envs/aqqa/lib/python3.8/urllib/parse.py:135\u001b[0m, in \u001b[0;36m_coerce_args\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m str_input:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args \u001b[38;5;241m+\u001b[39m (_noop,)\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_decode_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m (_encode_result,)\n",
      "File \u001b[0;32m/opt/conda/envs/aqqa/lib/python3.8/urllib/parse.py:119\u001b[0m, in \u001b[0;36m_decode_args\u001b[0;34m(args, encoding, errors)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decode_args\u001b[39m(args, encoding\u001b[38;5;241m=\u001b[39m_implicit_encoding,\n\u001b[1;32m    118\u001b[0m                        errors\u001b[38;5;241m=\u001b[39m_implicit_errors):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/aqqa/lib/python3.8/urllib/parse.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decode_args\u001b[39m(args, encoding\u001b[38;5;241m=\u001b[39m_implicit_encoding,\n\u001b[1;32m    118\u001b[0m                        errors\u001b[38;5;241m=\u001b[39m_implicit_errors):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m(encoding, errors) \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "def main(argv):\n",
    "\n",
    "    query = 'PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> PREFIX strdf: <http://strdf.di.uoa.gr/ontology#> PREFIX noa: <http://teleios.di.uoa.gr/ontologies/noaOntology.owl#> SELECT ?H (strdf:transform(?HGEO, <http://www.opengis.net/def/crs/EPSG/0/4326>) AS ?GEO) WHERE { ?H rdf:type noa:Hotspot . ?H noa:hasAcquisitionTime ?HAT . FILTER(str(?HAT) = \"2010-08-21T21:20:00\") . ?H noa:isDerivedFromSensor ?HS . FILTER(str(?HS) = \"MSG1_RSS\" ) . ?H noa:hasGeometry ?HGEO . }'\n",
    "    params = urllib.parse.urlparse({'SPARQLQuery': query, 'format': \"XML\"})\n",
    "    headers = {\"Content-type\": \"application/x-www-form-urlencoded\", \"Accept\": \"text/xml\"}\n",
    "\n",
    "    #conn = httplib.HTTPConnection(\"papos.space.noa.gr:8080\")\n",
    "    #conn.request(\"POST\", \"/endpoint/Query\", params, headers)\n",
    "\n",
    "    conn = httplib.HTTPConnection(\"test.strabon.di.uoa.gr\")\n",
    "    conn.request(\"POST\", \"/NOA/Query\", params, headers)\n",
    "\n",
    "    response = conn.getresponse()\n",
    "    print(response.status, response.reason)\n",
    "    print(response.msg)\n",
    "    print(response.read())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main(sys.argv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e51d11-f81e-4f1d-87c3-b1865e5c9366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f48120-8109-4a45-af91-acfa18c2b7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953cb660-8e48-4ec3-8016-252c2d70afe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aqqa",
   "language": "python",
   "name": "aqqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
